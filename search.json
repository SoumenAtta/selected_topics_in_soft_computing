[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Selected Topics in Soft Computing",
    "section": "",
    "text": "üìÖ Duration: March 2026 ‚Äì May 2026\nüìå Classes: 2 per week\nüèõÔ∏è Location: Faculty of Information Technology, University of Jyv√§skyl√§, Finland\nResponsible Teacher: Dr.¬†Soumen Atta, Ph.D.\n‚úâÔ∏è Email: soumen.s.atta@jyu.fi;soumen.atta@gmail.com\n\nWelcome to Selected Topics in Soft Computing. This course introduces mathematical programming, integer and mixed-integer optimization, and modern metaheuristic algorithms, with a strong emphasis on practical implementation using Python and Gurobi.\nUse the navigation bar to access the syllabus, schedule, lectures, and assignments.\nThis site is under construction."
  },
  {
    "objectID": "lectures/lecture1.html",
    "href": "lectures/lecture1.html",
    "title": "Lecture 1 ‚Äî Introduction to Optimization, LP, ILP, and MILP",
    "section": "",
    "text": "By the end of this lecture you should be able to\n\narticulate the core elements of an optimization model\n\ndistinguish linear programming, integer linear programming, and mixed integer linear programming\n\ndefine binary decision variables and explain why they are a special case of integer variables\n\nformulate small LP, ILP, and MILP models from text\n\nrecognize common modeling patterns for practice"
  },
  {
    "objectID": "lectures/lecture1.html#learning-objectives",
    "href": "lectures/lecture1.html#learning-objectives",
    "title": "Lecture 1 ‚Äî Introduction to Optimization, LP, ILP, and MILP",
    "section": "",
    "text": "By the end of this lecture you should be able to\n\narticulate the core elements of an optimization model\n\ndistinguish linear programming, integer linear programming, and mixed integer linear programming\n\ndefine binary decision variables and explain why they are a special case of integer variables\n\nformulate small LP, ILP, and MILP models from text\n\nrecognize common modeling patterns for practice"
  },
  {
    "objectID": "lectures/lecture1.html#what-is-optimization",
    "href": "lectures/lecture1.html#what-is-optimization",
    "title": "Lecture 1 ‚Äî Introduction to Optimization, LP, ILP, and MILP",
    "section": "2 What is Optimization",
    "text": "2 What is Optimization\nOptimization is the scientific discipline concerned with selecting the best possible decision from a set of feasible alternatives, subject to explicitly stated constraints. The notion of ‚Äúbest‚Äù is formalized through an objective function, while feasibility is determined by constraints that encode physical, economic, technological, or logical limitations of the system under study.\nIn mathematical terms, an optimization problem can be expressed as:\n\\[\n\\begin{aligned}\n\\min_{x \\in \\mathcal{X}} \\ \\ & f(x) \\\\\n\\text{s.t.}\\ \\ & g_i(x) \\le 0,\\quad i=1,\\dots,m,\n\\end{aligned}\n\\]\nwhere:\n\n\\(x\\) denotes the decision variables, representing quantities or choices under the control of the decision maker,\n\\(f(x)\\) is the objective function, a scalar-valued measure that quantifies performance, such as cost, profit, distance, time, risk, or energy consumption,\n\\(g_i(x)\\) are the constraints, which restrict admissible decisions by modeling system limitations, policy rules, or logical relationships, and\n\\(\\mathcal{X}\\) is the decision space, defining the domain of allowable values for \\(x\\), potentially including nonnegativity, upper bounds, integrality, or discreteness requirements.\n\nAn optimization problem is said to be feasible if there exists at least one \\(x \\in \\mathcal{X}\\) satisfying all constraints, and optimal if among all feasible solutions, it attains the best possible objective value.\nFrom a computational perspective, optimization provides a rigorous framework for transforming informal decision problems into well-defined mathematical models that can be analyzed and solved using algorithmic methods. The choice of the modeling framework (continuous, integer, or mixed-integer) has a fundamental impact on both the expressive power of the model and the computational complexity of solving it.\nOptimization thus lies at the core of operations research, mathematical programming, and algorithmic decision making, serving as a bridge between real-world decision problems and formal, solvable mathematical formulations.\n\n\n2.1 Why Optimization?\nOptimization problems arise naturally whenever limited resources must be allocated efficiently to achieve well-defined goals. In many real-world systems, decisions are constrained by budgets, capacities, physical laws, or policy rules, and optimization provides a principled way to navigate these trade-offs.\n\nOperations Research Optimization is central to classical operations research problems such as facility location, vehicle routing, production planning, scheduling, and workforce assignment. These problems involve coordinating multiple interdependent decisions to minimize costs or maximize service quality under resource and operational constraints.\nEconomics and Finance In economics and finance, optimization underlies portfolio selection, pricing strategies, cost minimization, revenue maximization, and equilibrium analysis. Decision makers seek optimal trade-offs between risk and return, or between competing economic objectives, subject to market and regulatory constraints.\nEngineering and Infrastructure Systems Engineering applications include the design and operation of networks (transportation, telecommunication, power grids), resource allocation in manufacturing systems, and optimization of energy generation and distribution. Here, optimization ensures efficient, reliable, and sustainable system performance.\nComputer Science, Data Science, and Artificial Intelligence Many problems in computer science are inherently optimization problems, including combinatorial optimization, algorithm design, and resource scheduling. In data science and artificial intelligence, training machine learning models often reduces to minimizing a loss function subject to regularization or structural constraints.\n\nAcross all these domains, optimization serves as a unifying framework that converts complex decision-making problems into mathematical models that can be analyzed, solved, and implemented using algorithmic methods.\n\n\n\n2.2 Key Elements of an Optimization Model\nAn optimization model is built by carefully translating a real-world decision problem into a precise mathematical structure. The quality of the resulting solution depends critically on how accurately these elements capture the underlying system.\n\nDecision Variables Decision variables represent the choices that are under the control of the decision maker. They are the fundamental unknowns whose values are to be determined by solving the optimization problem. Example: \\(x_j\\) denotes the number of units of product \\(j\\) to be produced during a planning period.\nObjective Function The objective function provides a quantitative measure of performance and defines what it means for a solution to be ‚Äúoptimal.‚Äù It aggregates the effects of decision variables into a single scalar value to be minimized or maximized. Example: minimizing total production cost or maximizing overall profit.\nConstraints Constraints describe the restrictions that feasible decisions must satisfy. They model physical limitations, resource availability, policy rules, technological relationships, or logical conditions inherent in the system. Example: machine capacity limits, labor availability, material balance equations, or demand satisfaction requirements.\nData Parameters Data parameters are known, fixed inputs to the model that characterize a specific problem instance. These parameters are not decision variables but influence the objective and constraints. Example: unit costs, processing times, customer demands, or available labor hours.\nSolution Method The solution method refers to the algorithmic approach or solver used to compute an optimal solution. The choice of method depends on the problem structure and size, and may range from exact algorithms to approximation or heuristic techniques. Example: simplex or interior-point methods for LP, branch-and-bound for ILP, or metaheuristic algorithms for large-scale problems.\nPost-analysis and Validation After obtaining a solution, it is essential to interpret and validate the results in the context of the original problem. This includes checking feasibility, assessing practical implementability, and performing sensitivity analysis to understand how changes in data parameters affect the solution.\n\nTogether, these elements form a coherent modeling framework that enables systematic analysis and informed decision making through optimization.\n\n\n\n2.3 The Modeling Workflow\nIn practice, developing an effective optimization model is an iterative and structured process rather than a one-shot activity. A systematic workflow helps ensure that the mathematical formulation faithfully represents the real decision problem and leads to meaningful, implementable solutions.\n\nUnderstand the problem context Clearly identify the decision-making setting, the objectives to be achieved, and the stakeholders involved. At this stage, it is essential to understand what is being optimized, which resources are limited, and what trade-offs are inherent in the system.\nDefine decision variables Translate the controllable decisions into well-defined mathematical variables. Each decision variable should have a clear interpretation and unit, and collectively they should fully describe all decisions to be optimized.\nFormulate the objective function Express the performance criterion mathematically as a function of the decision variables. The objective should align with the true goal of the decision maker, such as minimizing cost, maximizing profit, or improving service quality.\nExpress the constraints Model all relevant limitations and requirements using mathematical expressions. Constraints must accurately capture physical capacities, resource availability, logical relationships, and policy rules, without introducing unnecessary complexity.\nSelect a solution method or solver Choose an appropriate algorithmic approach based on the structure and scale of the problem. This may involve exact methods for small to medium instances, or approximation and heuristic methods for large or complex problems.\nInterpret results and validate Analyze the computed solution in the context of the original problem. Check feasibility, assess whether the solution is practically implementable, and perform sensitivity or scenario analysis to understand robustness with respect to data uncertainty.\nIterate and refine If the results do not align with real-world expectations or constraints, revise the model. Refinement may involve redefining variables, tightening constraints, adjusting objective terms, or incorporating additional system details.\n\nThis modeling workflow forms the conceptual foundation for all subsequent topics in this course, including Linear Programming (LP), Integer Linear Programming (ILP), and Mixed Integer Linear Programming (MILP), and remains applicable across a wide range of optimization problems and application domains."
  },
  {
    "objectID": "lectures/lecture1.html#linear-programming-lp",
    "href": "lectures/lecture1.html#linear-programming-lp",
    "title": "Lecture 1 ‚Äî Introduction to Optimization, LP, ILP, and MILP",
    "section": "3 Linear Programming (LP)",
    "text": "3 Linear Programming (LP)\nLinear Programming (LP) is one of the most fundamental and extensively studied classes of optimization problems. An LP model is characterized by a linear objective function, linear constraints, and continuous decision variables. Because of this structure, LP admits strong theoretical properties and highly efficient solution algorithms, making it a cornerstone of operations research and mathematical programming.\nIn an LP, decision variables are allowed to take fractional values, which makes LP particularly suitable for modeling divisible resources such as material flows, energy, time, or monetary quantities.\n\n\n3.1 Canonical Form\nA standard minimization LP can be written in canonical form as:\n\\[\n\\begin{aligned}\n\\min\\ \\ & c^\\top x \\\\\n\\text{s.t.}\\ \\ & Ax \\le b, \\\\\n& x \\ge 0,\n\\end{aligned}\n\\]\nwhere:\n\n\\(x \\in \\mathbb{R}^n\\) is the vector of decision variables,\n\\(c \\in \\mathbb{R}^n\\) contains the objective coefficients,\n\\(A \\in \\mathbb{R}^{m \\times n}\\) is the constraint coefficient matrix, and\n\\(b \\in \\mathbb{R}^m\\) is the right-hand side vector.\n\nThis form is not restrictive: equality constraints, \\(\\ge\\)-type inequalities, and free variables can all be transformed into this representation through standard reformulations.\n\n\n\n3.2 Key Properties of Linear Programming\n\nFeasible Region The set of all points satisfying the linear constraints defines the feasible region. Geometrically, this region is a convex polyhedron, formed by the intersection of finitely many half-spaces.\nExtreme Point Optimality If an LP has an optimal solution, then at least one optimal solution occurs at an extreme point (vertex) of the feasible region. This fundamental property underlies the design of vertex-based algorithms such as the simplex method.\nEfficient Algorithms Linear programs can be solved very efficiently in practice.\n\nThe simplex algorithm is widely used and often extremely fast on real instances.\nInterior-point methods provide polynomial-time complexity guarantees and are effective for large-scale LPs.\n\nDuality Theory Every LP has an associated dual problem, whose variables can be interpreted as shadow prices or marginal values of resources. Duality enables sensitivity analysis and provides deep insights into how changes in parameters affect the optimal solution.\n\n\n\n\n3.3 Example: Diet Problem\nA dietitian aims to design a diet that satisfies nutritional requirements at minimum cost.\n\nData:\n\n\\(c_j\\): cost per unit of food \\(j\\)\n\\(a_{ij}\\): amount of nutrient \\(i\\) contained in one unit of food \\(j\\)\n\\(r_i\\): minimum required intake of nutrient \\(i\\)\n\nDecision variables: \\(x_j \\ge 0\\) denotes the quantity of food \\(j\\) included in the diet.\nModel:\n\n\\[\n\\begin{aligned}\n\\min\\ \\ & \\sum_j c_j x_j \\\\\n\\text{s.t.}\\ \\ & \\sum_j a_{ij} x_j \\ge r_i,\\quad \\forall i, \\\\\n& x_j \\ge 0,\\quad \\forall j.\n\\end{aligned}\n\\]\nThis model illustrates how linear constraints can capture nutritional requirements, while the objective function represents total cost.\n\n\n\n3.4 Example: Production Planning\nA company produces two products, \\(A\\) and \\(B\\), using a limited amount of labor.\n\nData:\n\nProfit: \\(3\\) per unit of product \\(A\\), \\(5\\) per unit of product \\(B\\)\nLabor usage: \\(2\\) hours per unit of \\(A\\), \\(4\\) hours per unit of \\(B\\)\nTotal available labor: \\(100\\) hours\n\nDecision variables:\n\n\\(x_A\\) = number of units of product \\(A\\) produced\n\\(x_B\\) = number of units of product \\(B\\) produced\n\nModel:\n\n\\[\n\\begin{aligned}\n\\max\\ \\ & 3x_A + 5x_B \\\\\n\\text{s.t.}\\ \\ & 2x_A + 4x_B \\le 100, \\\\\n& x_A, x_B \\ge 0.\n\\end{aligned}\n\\]\nWith only two variables, this LP can be solved graphically by visualizing the feasible region and identifying the vertex that maximizes profit.\n\n\n\n3.5 Takeaways\n\nLinear programming provides a powerful framework for modeling problems with continuous decision variables and linear relationships.\nOptimal solutions, when they exist, are attained at extreme points of the feasible region.\nLP models are widely applicable in areas such as resource allocation, blending, scheduling, transportation, and logistics, and they form the basis for more advanced models such as ILP and MILP."
  },
  {
    "objectID": "lectures/lecture1.html#from-lp-to-ilp",
    "href": "lectures/lecture1.html#from-lp-to-ilp",
    "title": "Lecture 1 ‚Äî Introduction to Optimization, LP, ILP, and MILP",
    "section": "4 From LP to ILP",
    "text": "4 From LP to ILP\nInteger Linear Programming (ILP) extends linear programming by imposing integrality requirements on some or all decision variables, while preserving the linear structure of the objective function and constraints. This extension is essential for modeling decisions that are inherently discrete and cannot be meaningfully represented by fractional values.\nIn ILP, decision variables are restricted to take integer values, most commonly binary values.\n\nBinary variable. A binary variable is a special case of an integer variable that can only take values in the set \\({0,1}\\): \\[\nx \\in {0,1}\\quad \\text{encodes a yes‚Äìno or on‚Äìoff decision.}\n\\]\nBinary variables play a central role in optimization modeling because they allow the representation of selection, activation, logical conditions, and structural decisions.\nWhy integer variables? Integer variables are required whenever decisions involve:\n\non‚Äìoff or open‚Äìclose choices,\nlogical selection, such as choosing at most \\(p\\) items,\ncounting decisions, such as the number of workers, shifts, or vehicles,\ndiscrete and indivisible resources, such as machines, trucks, or facilities.\n\nComputational aspect. Unlike LP, ILP is NP hard in general. The introduction of integrality destroys convexity and makes the problem combinatorial in nature. Modern solvers address this challenge using sophisticated algorithmic frameworks that combine branch-and-bound, branch-and-cut (cutting planes), presolve techniques, primal heuristics, and strong formulations to solve many practically relevant instances efficiently.\n\nModeling guideline. Whenever the underlying phenomenon is discrete by nature‚Äîsuch as assignment, selection, routing, or facility opening‚Äîimposing integrality constraints is the correct modeling abstraction. Binary variables are particularly effective for controlling activation, enforcing either‚Äìor logic, and linking continuous decisions to discrete choices.\n\n\n4.1 Binary Variables: Common Modeling Patterns\nBinary variables give rise to a set of standard modeling patterns that recur across a wide range of applications. Mastery of these patterns is essential for effective ILP and MILP modeling.\n\nSelection (cardinality constraint). Choose at most \\(p\\) items from a given set: \\[\n\\sum_j y_j \\le p,\\quad y_j \\in {0,1}.\n\\]\nActivation (on‚Äìoff constraint using big-\\(M\\)). A continuous decision variable \\(x_j\\) is allowed to take positive values only if the corresponding binary variable is active: \\[\nx_j \\le M, y_j,\\quad y_j \\in {0,1},\\ x_j \\ge 0.\n\\]\nRemark. When supported by the solver, indicator constraints (e.g., \\(y_j=0 \\Rightarrow x_j=0\\)) are preferable, as they avoid explicit big-\\(M\\) values. If big-\\(M\\) is used, it should be chosen as tightly as possible to strengthen the formulation.\nEither‚Äìor constraint (disjunctive modeling). Enforce that at least one of two linear constraints must hold: \\[\na^\\top x \\le b + M(1-y),\\quad\nd^\\top x \\le e + My,\\quad y \\in {0,1}.\n\\] When \\(y=0\\), the first constraint is enforced; when \\(y=1\\), the second constraint is enforced.\nLogical implication. Model conditional constraints such as ‚Äúif \\(y=1\\), then \\(x \\ge L\\)‚Äù: \\[\nx \\ge L, y,\\quad y \\in {0,1}.\n\\] Similarly, ‚Äúif \\(y=0\\), then \\(x=0\\)‚Äù can be modeled as \\(x \\le U,y\\).\n\nStrengthening tip. Whenever possible, replace generic big-\\(M\\) constants with known physical or structural bounds (e.g., using a capacity \\(U_j\\) as the natural upper bound). Tight bounds significantly improve the quality of LP relaxations.\n\n\n\n4.2 ILP Example 1: Assignment Problem\nProblem. Assign each worker to exactly one task, and each task to exactly one worker, such that the total assignment cost is minimized.\n\nData. \\(c_{ij}\\) denotes the cost of assigning worker \\(i\\) to task \\(j\\).\nDecision variables. \\(x_{ij} \\in {0,1}\\) equals 1 if worker \\(i\\) is assigned to task \\(j\\).\nModel. \\[\n\\begin{aligned}\n\\min\\ \\ & \\sum_i \\sum_j c_{ij} x_{ij} \\\\\n\\text{s.t.}\\ \\ & \\sum_j x_{ij} = 1,\\quad \\forall i,\\\\\n& \\sum_i x_{ij} = 1,\\quad \\forall j,\\\\\n& x_{ij} \\in {0,1}.\n\\end{aligned}\n\\]\n\nNotes. This is a classical 0‚Äì1 ILP. The constraint matrix is totally unimodular, implying that the LP relaxation already yields integer solutions. As a result, the problem can be solved efficiently using linear programming techniques.\n\n\n\n4.3 ILP Example 2: Set Covering\nProblem. Select the minimum-cost set of stations such that every demand point is covered by at least one open station.\n\nData. \\(a_{ij} = 1\\) if station \\(j\\) covers demand point \\(i\\) (and \\(0\\) otherwise); \\(c_j\\) is the cost of opening station \\(j\\).\nDecision variables. \\(y_j \\in {0,1}\\) equals 1 if station \\(j\\) is opened.\nModel. \\[\n\\begin{aligned}\n\\min\\ \\ & \\sum_j c_j y_j \\\\\n\\text{s.t.}\\ \\ & \\sum_j a_{ij} y_j \\ge 1,\\quad \\forall i,\\\\\n& y_j \\in {0,1}.\n\\end{aligned}\n\\]\n\nNotes. The covering constraints define a classical packing/covering structure. Strengthened formulations and cutting planes are often crucial for solving large-scale instances efficiently.\n\n\n\n4.4 ILP Example 3: Knapsack with Selection\nProblem. Choose a subset of items to maximize total value subject to a capacity constraint.\n\nData. \\(v_j\\) denotes the value of item \\(j\\), \\(w_j\\) denotes its weight, \\(W\\) is the knapsack capacity.\nDecision variables. \\(x_j \\in {0,1}\\) indicates whether item \\(j\\) is selected.\nModel. \\[\n\\begin{aligned}\n\\max\\ \\ & \\sum_j v_j x_j \\\\\n\\text{s.t.}\\ \\ & \\sum_j w_j x_j \\le W,\\\\\n& x_j \\in {0,1}.\n\\end{aligned}\n\\]\n\nNotes. Despite its compact formulation, the knapsack problem is NP hard and appears as a fundamental substructure in many more complex integer and mixed-integer optimization models."
  },
  {
    "objectID": "lectures/lecture1.html#mixed-integer-linear-programming-milp",
    "href": "lectures/lecture1.html#mixed-integer-linear-programming-milp",
    "title": "Lecture 1 ‚Äî Introduction to Optimization, LP, ILP, and MILP",
    "section": "5 Mixed Integer Linear Programming (MILP)",
    "text": "5 Mixed Integer Linear Programming (MILP)\nMixed Integer Linear Programming (MILP) extends integer linear programming by allowing continuous and integer decision variables to coexist within a single linear optimization model. This modeling framework is particularly powerful because many real-world decision problems naturally involve a combination of discrete design choices and continuous operational decisions.\nIn MILP, binary or integer variables typically represent strategic or structural decisions (such as opening facilities or activating setups), while continuous variables model operational quantities (such as production levels or material flows).\n\nGeneral template. \\[\n\\begin{aligned}\n\\min\\ \\ & c^\\top x + d^\\top y \\\\\n\\text{s.t.}\\ \\ & A x + B y \\le b,\\\\\n& x \\in \\mathbb{R}^n_{\\ge 0},\\quad y \\in {0,1}^m.\n\\end{aligned}\n\\]\nHere, \\(x\\) represents continuous decision variables, while \\(y\\) represents binary (or more generally, integer) decision variables.\nTypical use cases. MILP is the standard modeling paradigm for problems such as facility location with flow decisions, production planning with setup costs, blending problems with on‚Äìoff recipes, network design, scheduling with changeovers, and many integrated planning problems in logistics and manufacturing.\n\nRelaxation insight. The LP relaxation of an MILP is obtained by dropping the integrality requirements on the variables \\(y\\). For minimization problems, this relaxation provides a lower bound on the optimal objective value. Strong formulations and tight constraints reduce the gap between the LP relaxation and the integer optimum, thereby significantly improving computational performance.\n\n\n5.1 MILP Example 1: Facility Location with Flow\nProblem. Decide which facilities to open and how much to ship from each open facility to customers in order to satisfy all demands at minimum total cost.\n\nData.\n\n\\(f_j\\): fixed cost of opening facility \\(j\\)\n\\(U_j\\): capacity of facility \\(j\\)\n\\(c_{ij}\\): unit shipping cost from facility \\(j\\) to customer \\(i\\)\n\\(d_i\\): demand of customer \\(i\\)\n\nDecision variables.\n\n\\(y_j \\in {0,1}\\) equals 1 if facility \\(j\\) is opened\n\\(x_{ij} \\ge 0\\) denotes the quantity shipped from facility \\(j\\) to customer \\(i\\)\n\nModel. \\[\n\\begin{aligned}\n\\min\\ \\ & \\sum_j f_j y_j + \\sum_i \\sum_j c_{ij} x_{ij} \\\\\n\\text{s.t.}\\ \\ & \\sum_j x_{ij} \\ge d_i,\\quad \\forall i,\\\\\n& \\sum_i x_{ij} \\le U_j, y_j,\\quad \\forall j,\\\\\n& x_{ij} \\ge 0,\\quad y_j \\in {0,1}.\n\\end{aligned}\n\\]\n\nNotes. The constraint \\(\\sum_i x_{ij} \\le U_j y_j\\) links the continuous flow variables to the binary opening decisions and ensures that no flow is allowed through a closed facility. This is an example of an on‚Äìoff constraint with a natural big-\\(M\\), where \\(M = U_j\\). When available, indicator constraints (e.g., \\(y_j = 0 \\Rightarrow x_{ij} = 0\\) for all \\(i\\)) can be used as an alternative formulation.\n\n\n\n5.2 MILP Example 2: Production Planning with Setups\nProblem. Plan production quantities over multiple periods and decide whether to set up production in each period. Setting up production incurs a fixed cost, and production is limited by a maximum capacity when the setup is active.\n\nData.\n\n\\(F_t\\): fixed setup cost in period \\(t\\)\n\\(c_t\\): variable production cost per unit in period \\(t\\)\n\\(d_t\\): demand in period \\(t\\)\n\\(U_t\\): maximum production capacity in period \\(t\\) if production is set up\n\nDecision variables.\n\n\\(y_t \\in {0,1}\\) equals 1 if production is set up in period \\(t\\)\n\\(x_t \\ge 0\\) denotes the production quantity in period \\(t\\)\n\nModel. \\[\n\\begin{aligned}\n\\min\\ \\ & \\sum_t \\left(F_t y_t + c_t x_t\\right) \\\\\n\\text{s.t.}\\ \\ & \\sum_{\\tau=1}^t x_\\tau \\ge \\sum_{\\tau=1}^t d_\\tau,\\quad \\forall t,\\\\\n& x_t \\le U_t, y_t,\\quad \\forall t,\\\\\n& x_t \\ge 0,\\quad y_t \\in {0,1}.\n\\end{aligned}\n\\]\n\nNotes. The cumulative demand constraints ensure that demand is met up to each period when backlogging is not allowed. The constraint \\(x_t \\le U_t y_t\\) links production to setup decisions and prevents production in periods without setup. If inventory and backlogging are permitted, additional state variables and inventory balance equations must be introduced.\n\nMILP provides a unifying framework for modeling complex decision problems that involve both strategic discrete choices and tactical or operational continuous decisions, making it one of the most important tools in modern operations research and optimization practice.\n\n\n\n5.3 Practical Remarks for ILP and MILP Modeling\nEffective integer and mixed-integer modeling goes beyond writing mathematically correct formulations. Computational performance and solution quality depend heavily on how the model is structured and parameterized.\n\nBig-\\(M\\) selection. Big-\\(M\\) constants should always be chosen as tight as possible. Excessively large values weaken the LP relaxation, lead to poor bounds, and significantly slow down the branch-and-bound search. Whenever feasible, replace generic big-\\(M\\) values with natural physical or logical bounds derived from the problem data.\nIndicator constraints. When supported by the solver, indicator constraints are preferable to explicit big-\\(M\\) formulations. They express logical conditions directly (e.g., ‚Äúif \\(y=0\\), then \\(x=0\\)‚Äù), avoid manual tuning of constants, and often result in stronger relaxations and better numerical behavior.\nScaling and variable bounds. Provide meaningful lower and upper bounds for all variables whenever possible. Coefficients in objectives and constraints should be scaled to similar orders of magnitude to improve numerical stability and solver robustness.\nFormulation strength. Different formulations of the same problem can vary drastically in computational difficulty. Strong formulations that incorporate valid inequalities, tightened constraints, or extended variable sets can dramatically reduce solution time by improving the quality of LP relaxations.\nStopping criteria and solution assessment. For large-scale models, it is often practical to impose time limits and acceptable optimality gaps. Always assess the feasibility and quality of the obtained solution and interpret results in the context of the underlying decision problem rather than relying solely on solver status.\n\n\n\n\n5.4 LP vs ILP vs MILP: Quick Comparison\nThe three major classes of linear optimization models differ primarily in the nature of their decision variables and the resulting computational complexity. The table below summarizes their key characteristics.\n\n\n\n\n\n\n\n\n\nAspect\nLP\nILP\nMILP\n\n\n\n\nDecision variables\nContinuous\nInteger (often binary)\nMixture of continuous and integer\n\n\nObjective function\nLinear\nLinear\nLinear\n\n\nConstraints\nLinear\nLinear\nLinear\n\n\nComputational complexity\nPolynomial time in theory for certain algorithms\nNP hard\nNP hard\n\n\nTypical use cases\nFlow problems, blending, fractional resource allocation\nSelection, assignment, routing, scheduling\nIntegrated design and operations, facility location with flows, production planning with setups\n\n\nModeling role\nPurely operational decisions\nPurely discrete decisions\nJoint strategic and operational decisions\n\n\n\nThis comparison highlights how LP serves as the foundational model class, while ILP and MILP extend it to capture discrete decision making and integrated planning problems encountered in real-world applications."
  },
  {
    "objectID": "lectures/lecture1.html#mini-exercises",
    "href": "lectures/lecture1.html#mini-exercises",
    "title": "Lecture 1 ‚Äî Introduction to Optimization, LP, ILP, and MILP",
    "section": "6 Mini Exercises",
    "text": "6 Mini Exercises\n\nProject selection under a budget (ILP). A set of projects \\(J\\) is available. Project \\(j\\) yields profit \\(v_j\\) and requires effort \\(e_j\\). At most \\(p\\) projects can be selected, and the total effort cannot exceed \\(B\\).\n\nIntroduce binary decision variables: \\[\nx_j \\in {0,1}\\quad \\forall j \\in J,\n\\] where \\(x_j=1\\) if project \\(j\\) is selected.\nFormulate an ILP that maximizes total profit subject to:\n\na cardinality constraint (select at most \\(p\\) projects), and\na budget constraint (total effort at most \\(B\\)).\n\n\nTask. Write the full mathematical model: objective function, constraints, and variable domains.\nSet covering with penalties (MILP). Consider the standard set covering model with demand points \\(i\\) and stations \\(j\\), where \\(a_{ij}=1\\) if station \\(j\\) covers demand point \\(i\\). In standard set covering, every demand point must be covered. In this exercise, coverage is optional but leaving demand point \\(i\\) uncovered incurs penalty \\(P_i\\).\nTask. Propose a MILP formulation by introducing either:\n\nbinary uncovered indicators \\(u_i \\in {0,1}\\), where \\(u_i=1\\) means demand point \\(i\\) is uncovered, or\ncontinuous slack variables representing uncovered status with an appropriate linearization.\n\nThe objective should minimize the total opening cost plus uncovered penalties, and the constraints should ensure each demand point is either covered or counted as uncovered."
  },
  {
    "objectID": "lectures/lecture4.html",
    "href": "lectures/lecture4.html",
    "title": "Lecture 4 ‚Äî Introduction to Heuristics and Metaheuristics",
    "section": "",
    "text": "By the end of this lecture, students should be able to:\n\nunderstand the role of heuristics in solving hard optimization problems\n\ndistinguish between constructive heuristics and improvement heuristics\n\nexplain the concepts of exploration and exploitation in search algorithms\n\nrecognize common failure modes of naive heuristics\n\nunderstand what metaheuristics are and how they generalize heuristic design\n\nplace heuristics and metaheuristics within the broader soft computing paradigm"
  },
  {
    "objectID": "lectures/lecture4.html#learning-objectives",
    "href": "lectures/lecture4.html#learning-objectives",
    "title": "Lecture 4 ‚Äî Introduction to Heuristics and Metaheuristics",
    "section": "",
    "text": "By the end of this lecture, students should be able to:\n\nunderstand the role of heuristics in solving hard optimization problems\n\ndistinguish between constructive heuristics and improvement heuristics\n\nexplain the concepts of exploration and exploitation in search algorithms\n\nrecognize common failure modes of naive heuristics\n\nunderstand what metaheuristics are and how they generalize heuristic design\n\nplace heuristics and metaheuristics within the broader soft computing paradigm"
  },
  {
    "objectID": "lectures/lecture4.html#why-heuristics",
    "href": "lectures/lecture4.html#why-heuristics",
    "title": "Lecture 4 ‚Äî Introduction to Heuristics and Metaheuristics",
    "section": "2 Why Heuristics?",
    "text": "2 Why Heuristics?\nAs discussed in the previous lecture, many real-world optimization problems are NP hard and cannot be solved to proven optimality using exact methods within acceptable time limits. As problem size, uncertainty, and modeling complexity increase, the computational cost of exact optimization often grows beyond what is practically feasible.\nIn such settings, the objective of optimization shifts from proving optimality to obtaining high-quality solutions efficiently. The emphasis moves toward scalability, robustness, and responsiveness rather than mathematical guarantees.\nHeuristics play a central role in this shift. They are algorithmic strategies designed to rapidly identify good solutions by exploiting problem structure, domain knowledge, intuition, or empirically effective rules.\nTypical properties of heuristics include:\n\nfast and scalable behavior, even on large instances,\nproblem-specific design, tailored to exploit structural characteristics, and\nabsence of optimality guarantees, in exchange for practical efficiency.\n\nDespite the lack of theoretical guarantees, heuristics are indispensable in practice and frequently outperform exact methods on large-scale or time-critical problems.\n\n\n2.1 What Is a Heuristic?\nA heuristic is a rule, procedure, or algorithm that guides the search for solutions using experience-driven or intuitive principles rather than exhaustive enumeration or complete mathematical analysis.\nKey characteristics of heuristics include:\n\nthey target good or satisfactory solutions, not provably optimal ones,\nthey explicitly trade optimality guarantees for speed and simplicity,\nthey are often designed for a specific problem class or application domain, and\ntheir performance is typically assessed through empirical evaluation rather than theoretical bounds.\n\nHeuristics can be broadly classified into two fundamental categories: constructive heuristics and improvement heuristics.\n\n\n\n2.2 Constructive Heuristics\nDefinition:\nA constructive heuristic builds a feasible solution incrementally, starting from an empty or partial solution and adding elements until a complete solution is obtained.\nThe typical workflow is:\n\nstart with an empty or partially defined solution,\nrepeatedly add decision components according to a predefined rule,\nterminate once all constraints are satisfied and the solution is complete.\n\nConstructive heuristics are often used to generate initial solutions, which may later be refined using improvement heuristics or metaheuristics.\n\nExamples of Constructive Heuristics:\n\nGreedy algorithms\n\nselect the locally best option at each step based on a simple criterion,\nexamples include choosing the cheapest facility, the nearest customer, or the item with the highest value-to-weight ratio.\n\nPriority-rule-based heuristics\n\nrank decisions according to a priority index or score,\nexamples include scheduling jobs by shortest processing time or earliest due date.\n\nSequential insertion heuristics\n\niteratively insert elements into a growing partial solution,\ncommonly used in routing, sequencing, and layout problems.\n\n\n\nStrengths and Limitations:\nStrengths\n\nextremely fast and easy to implement,\ntypically produce feasible solutions almost immediately,\nwell suited for warm starts in exact solvers or local search methods.\n\nLimitations\n\nmyopic decision-making may lead to poor global solution quality,\nstrong sensitivity to tie-breaking rules and ordering decisions,\nlimited ability to recover once early poor choices are made.\n\n\n\n\n2.3 Improvement Heuristics\nDefinition:\nAn improvement heuristic begins with an existing feasible solution and iteratively improves it by applying local modifications that reduce the objective value or improve solution quality.\nThe general pattern is:\n\nstart from an initial feasible solution,\ndefine a neighborhood of similar solutions,\nmove to an improved solution if one exists in the neighborhood,\nrepeat until no improving move is found.\n\nImprovement heuristics are commonly referred to as local search methods.\n\nNeighborhood Structures:\nA neighborhood structure specifies which solutions are considered ‚Äúclose‚Äù to the current solution and can be reached via a single move.\nTypical neighborhood operations include:\n\nswapping two assignments or elements,\nreassigning a customer to a different facility,\nflipping a binary decision variable,\ninserting or removing an element from a solution.\n\nThe choice of neighborhood is critical: it determines both the quality of solutions that can be reached and the computational cost per iteration.\n\nLocal Optimality:\nAn improvement heuristic usually terminates at a local optimum, defined as a solution for which no neighboring solution yields improvement with respect to the chosen neighborhood.\nA key observation is:\n\nA local optimum is not necessarily a global optimum.\n\nThe presence of many local optima is a defining feature of hard combinatorial optimization problems and a major challenge for heuristic design.\n\n\n\n2.4 Exploration vs Exploitation\nA central concept in soft computing and heuristic optimization is the balance between exploration and exploitation.\nExploitation:\nExploitation focuses on intensively searching around high-quality solutions:\n\naggressively improving the current best solution,\nfavoring moves that yield immediate improvement,\ntypical of greedy strategies and steepest-descent local search.\n\nRisk: excessive exploitation leads to premature convergence and entrapment in poor local optima.\n\nExploration:\nExploration aims to diversify the search and discover new regions of the solution space:\n\nallowing non-improving or worsening moves,\nintroducing randomness or controlled perturbations,\nusing memory or population-based mechanisms.\n\nRisk: excessive exploration leads to slow convergence and inefficient use of computational effort.\n\nThe Trade-Off:\nEffective heuristic and metaheuristic algorithms are distinguished by how well they balance exploration and exploitation:\n\ntoo much exploitation leads to stagnation,\ntoo much exploration leads to inefficiency.\n\nDesigning mechanisms that dynamically balance these two forces is the central challenge of metaheuristic algorithm design and a core theme of soft computing.\n\n\n\n2.5 Limitations of Simple Heuristics\nWhile simple heuristics such as greedy algorithms and basic local search methods are attractive due to their simplicity and speed, they often suffer from fundamental limitations when applied to complex or large-scale optimization problems.\nCommon failure modes include:\n\nEntrapment in local optima. Greedy and basic improvement heuristics accept only improving moves. Once a local optimum is reached, no further progress is possible, even if significantly better solutions exist elsewhere in the solution space.\nCycling behavior. Without appropriate control mechanisms, local search heuristics may repeatedly revisit the same solutions or oscillate between a small set of configurations, leading to wasted computation without genuine improvement.\nLack of diversification. Simple heuristics typically focus on a narrow region of the solution space and lack mechanisms to explore alternative regions. As a result, they may miss high-quality solutions that are structurally different from the initial or current solution.\nHigh sensitivity to initial solutions. The final solution quality often depends heavily on the starting point. Poor initial solutions can lead to poor local optima, while better starting solutions may yield significantly better outcomes.\n\nThese limitations highlight the need for more sophisticated strategies that can escape local optima, manage search history, and balance intensification with diversification. This motivates the development of metaheuristics, which introduce higher-level control mechanisms to guide and enhance heuristic search behavior across complex solution landscapes."
  },
  {
    "objectID": "lectures/lecture4.html#what-are-metaheuristics",
    "href": "lectures/lecture4.html#what-are-metaheuristics",
    "title": "Lecture 4 ‚Äî Introduction to Heuristics and Metaheuristics",
    "section": "3 What Are Metaheuristics?",
    "text": "3 What Are Metaheuristics?\nA metaheuristic is a high-level algorithmic framework designed to guide, coordinate, and control the behavior of heuristics in order to improve solution quality, robustness, and scalability. Rather than solving a problem directly, a metaheuristic defines how heuristics should search the solution space.\nKey characteristics of metaheuristics include:\n\nproblem-independence at a conceptual level, meaning the same framework can be adapted to many different optimization problems,\nexplicit management of exploration and exploitation, balancing intensification around good solutions with diversification across the search space,\nmechanisms to escape local optima, such as controlled randomness, memory structures, or population diversity, and\nflexibility in implementation, allowing incorporation of problem-specific heuristics where beneficial.\n\nMetaheuristics do not replace heuristics. Instead, they orchestrate heuristics, providing strategic control over when, where, and how heuristic moves are applied.\n\n\n3.1 Examples of Metaheuristic Paradigms\nOver time, several major families of metaheuristics have emerged, each based on a different principle for controlling search behavior.\n\nTrajectory-based methods These methods operate on a single solution that evolves over time.\n\nSimulated annealing introduces probabilistic acceptance of worsening moves to escape local optima.\nTabu search uses adaptive memory structures to prevent cycling and encourage exploration of new regions.\n\nPopulation-based methods These methods maintain and evolve a set of solutions simultaneously.\n\nGenetic algorithms apply selection, crossover, and mutation operators inspired by biological evolution.\nEvolutionary strategies emphasize mutation and self-adaptation of search parameters.\n\nHybrid methods These approaches combine global exploration mechanisms with local improvement procedures.\n\nOften referred to as memetic algorithms, they integrate local search into population-based or trajectory-based frameworks to achieve both diversification and intensification.\n\n\nEach paradigm implements exploration and exploitation differently, leading to distinct performance characteristics across problem types.\n\n\n\n3.2 Heuristics vs Metaheuristics\nThe relationship between heuristics and metaheuristics can be summarized as follows:\n\n\n\n\n\n\n\n\nAspect\nHeuristics\nMetaheuristics\n\n\n\n\nScope\nProblem-specific\nGeneral algorithmic framework\n\n\nDesign effort\nLow to moderate\nModerate to high\n\n\nExploration control\nLimited or implicit\nExplicit and systematic\n\n\nRisk of stagnation\nHigh\nLower\n\n\nTypical role\nInitial solutions, fast improvements\nPrimary optimization engine\n\n\n\nIn practice, effective optimization systems rarely rely on one alone. Instead, heuristics and metaheuristics are combined, with heuristics providing problem-specific intelligence and metaheuristics supplying global search control.\n\n\n\n3.3 Soft Computing Perspective\nFrom the perspective of soft computing:\n\nheuristics encode human intuition, experience, and domain knowledge,\nmetaheuristics provide adaptive and self-regulating search mechanisms,\nsolution quality is assessed through empirical performance rather than formal optimality proofs, and\nrobustness, scalability, and flexibility are prioritized over exactness.\n\nThis philosophy contrasts with the rigor of exact optimization but complements it in modern decision-making systems, particularly for large-scale, uncertain, or highly complex optimization problems where exact methods are no longer practical.\n\n\n\n3.4 Takeaways\n\nHeuristics are essential for solving large-scale hard problems\n\nConstructive heuristics build solutions from scratch\n\nImprovement heuristics refine existing solutions\n\nLocal optima limit naive local search\n\nExploration and exploitation must be balanced\n\nMetaheuristics provide general, robust search frameworks"
  },
  {
    "objectID": "lectures/lecture4.html#mini-exercises",
    "href": "lectures/lecture4.html#mini-exercises",
    "title": "Lecture 4 ‚Äî Introduction to Heuristics and Metaheuristics",
    "section": "4 Mini Exercises",
    "text": "4 Mini Exercises\n\nGreedy heuristic and its limitations. Choose an optimization problem of your interest (for example, knapsack, scheduling, facility location, or routing).\n\nDescribe a simple greedy heuristic for this problem.\nExplain which local decision rule it uses and why it appears reasonable.\nDiscuss a scenario or instance where this greedy heuristic fails to produce a high-quality solution.\n\nNeighborhood design for a binary decision problem. Consider an optimization problem in which solutions are represented by binary vectors.\n\nPropose a neighborhood structure (for example, single-bit flips, swaps, or multi-bit moves).\nDescribe a local search strategy that explores this neighborhood to improve solution quality.\nExplain how the choice of neighborhood affects convergence speed and solution quality.\n\nRole of randomness in escaping local optima. Local search methods often get trapped in local optima.\n\nExplain how introducing randomness (for example, random restarts, probabilistic acceptance of worse solutions, or random perturbations) can help overcome this issue.\nDiscuss the trade-off between randomness and systematic improvement.\n\nExploration versus exploitation in heuristics. Take any heuristic or metaheuristic you are familiar with.\n\nIdentify which components of the algorithm focus on exploitation (intensifying search around good solutions).\nIdentify which components promote exploration (diversifying the search across the solution space).\nExplain why both components are necessary for effective optimization."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Lecture\nDate\nDay\nTime\nLocation\nTeacher\n\n\n\n\n1\n16.03.2026\nMon\n14.15‚Äì15.45\nAgora, Ag D215.1\nSoumen Atta\n\n\n2\n18.03.2026\nWed\n14.15‚Äì15.45\nAgora, Ag B122.1 Alfa\nSoumen Atta\n\n\n3\n23.03.2026\nMon\n14.15‚Äì15.45\nAgora, Ag D221.3\nSoumen Atta\n\n\n4\n25.03.2026\nWed\n14.15‚Äì15.45\nAgora, Ag D211.1\nSoumen Atta\n\n\n5\n08.04.2026\nWed\n14.15‚Äì15.45\nAgora, Ag D121.1 Pertti Kettusen sali\nSoumen Atta\n\n\n6\n13.04.2026\nMon\n14.15‚Äì15.45\nAgora, Ag D213.1\nSoumen Atta\n\n\n7\n15.04.2026\nWed\n14.15‚Äì15.45\nAgora, Ag B121.1 Beeta\nSoumen Atta\n\n\n8\n20.04.2026\nMon\n14.15‚Äì15.45\nAgora, Ag C222.1\nSoumen Atta\n\n\n9\n22.04.2026\nWed\n14.15‚Äì15.45\nAgora, Ag C222.1\nSoumen Atta\n\n\n10\n27.04.2026\nMon\n14.15‚Äì15.45\nAgora, Ag C222.1\nSoumen Atta\n\n\n11\n29.04.2026\nWed\n14.15‚Äì15.45\nAgora, Ag C222.1\nSoumen Atta\n\n\n12\n04.05.2026\nMon\n14.15‚Äì15.45\nAgora, Ag C222.1\nSoumen Atta\n\n\n13\n06.05.2026\nWed\n14.15‚Äì15.45\nAgora, Ag C222.1\nSoumen Atta\n\n\n14\n11.05.2026\nMon\n14.15‚Äì15.45\nAgora, Ag C222.1\nSoumen Atta"
  },
  {
    "objectID": "lectures/lecture2.html",
    "href": "lectures/lecture2.html",
    "title": "Lecture 2 ‚Äî Mathematical Programming with Python and Gurobi",
    "section": "",
    "text": "By the end of this lecture, students should be able to:\n\nunderstand the role of mathematical programming solvers in optimization\n\nexplain the architecture of a solver-based modeling workflow\n\ninstall and configure Gurobi with Python\n\nformulate and solve LP, ILP, and MILP models using the Gurobi Python API\n\ninterpret solver output and diagnose basic modeling issues\n\ndistinguish modeling concerns from algorithmic concerns"
  },
  {
    "objectID": "lectures/lecture2.html#learning-objectives",
    "href": "lectures/lecture2.html#learning-objectives",
    "title": "Lecture 2 ‚Äî Mathematical Programming with Python and Gurobi",
    "section": "",
    "text": "By the end of this lecture, students should be able to:\n\nunderstand the role of mathematical programming solvers in optimization\n\nexplain the architecture of a solver-based modeling workflow\n\ninstall and configure Gurobi with Python\n\nformulate and solve LP, ILP, and MILP models using the Gurobi Python API\n\ninterpret solver output and diagnose basic modeling issues\n\ndistinguish modeling concerns from algorithmic concerns"
  },
  {
    "objectID": "lectures/lecture2.html#optimization-models-and-solvers",
    "href": "lectures/lecture2.html#optimization-models-and-solvers",
    "title": "Lecture 2 ‚Äî Mathematical Programming with Python and Gurobi",
    "section": "2 Optimization Models and Solvers",
    "text": "2 Optimization Models and Solvers\nMathematical optimization models such as LPs, ILPs, and MILPs are abstract mathematical formulations that precisely describe a decision problem in terms of variables, objectives, and constraints. By themselves, these models do not produce solutions. To compute optimal or near-optimal decisions in practice, a model must be processed by a solver.\nA solver is responsible for transforming the abstract mathematical description into concrete algorithmic steps that explore the feasible region, evaluate candidate solutions, and certify optimality or infeasibility.\nA modern optimization workflow therefore consists of two conceptually distinct but tightly connected layers:\n\nModeling layer The decision problem is formulated mathematically: decision variables are defined, objectives are specified, and constraints are expressed. At this stage, the focus is on correctness, clarity, and faithful representation of the real-world problem.\nSolver layer The mathematical model is processed by algorithmic machinery that searches for optimal solutions. This layer is concerned with computational efficiency, numerical stability, and convergence guarantees.\n\nThis separation of concerns is fundamental. It allows the same mathematical model to be solved using different algorithms or solvers, and enables the same solver to be applied across a wide range of application domains without changing the underlying algorithms.\n\n\n2.1 What Is a Solver?\nAn optimization solver is a complex software system that automates the solution of mathematical optimization problems. At a high level, a solver:\n\naccepts a formal mathematical model as input, including variables, objective functions, and constraints,\napplies sophisticated algorithmic techniques such as simplex, interior-point methods, branch-and-bound, branch-and-cut, and cutting-plane methods, and\nreturns a solution together with detailed information about feasibility, optimality, bounds, and convergence status.\n\nBeyond computing solutions, modern solvers also provide diagnostic tools for detecting infeasibility, numerical issues, or modeling errors.\nWell-known optimization solvers include commercial solvers such as Gurobi and CPLEX, as well as open-source solvers such as GLPK and CBC. These solvers differ in performance, supported features, and licensing, but they all implement the same underlying mathematical programming paradigms.\nIn this course, the primary solver used will be Gurobi, selected for its state-of-the-art performance, robustness, and comprehensive support for Python-based modeling.\n\n\n\n2.2 Gurobi Overview\nGurobi is a commercial-grade optimization solver designed for solving linear, integer, and mixed-integer programming problems at scale. It is widely regarded as one of the fastest and most reliable solvers available for MILP.\nKey characteristics of Gurobi include:\n\nfull support for LP, ILP, and MILP formulations,\nadvanced presolve routines that simplify models before optimization,\npowerful cutting-plane strategies that strengthen LP relaxations,\nparallel branch-and-bound algorithms that exploit modern multi-core architectures, and\nwell-designed application programming interfaces (APIs) for Python, C++, Java, and other languages.\n\nGurobi is extensively used in industry for large-scale planning and optimization problems, and it is also widely adopted in academic research. Academic licenses are available free of charge, making it suitable for teaching and research purposes.\n\n\n\n2.3 Python as a Modeling Language\nIn this course, Python is used as the primary modeling language for mathematical programming. Rather than writing models in a dedicated algebraic modeling language, optimization models are constructed programmatically using Python objects, expressions, and control structures.\nPython-based modeling offers several important advantages:\n\nseamless integration with data processing and scientific computing libraries such as NumPy and pandas,\neasy automation of experiments, parameter studies, and batch runs,\nnatural integration with heuristics and metaheuristics implemented in Python, and\nimproved reproducibility, readability, and extensibility of optimization code.\n\nWithin this setup, Python acts as a high-level interface that expresses the optimization model, while the computationally intensive solution process is handled by Gurobi‚Äôs highly optimized solver core.\n\n\n\n2.4 Installing and Configuring Gurobi\nTo use Gurobi with Python, the following steps are required:\n\nInstall the Gurobi Optimizer on the system.\nObtain and activate an academic license.\nInstall the Gurobi Python package (gurobipy).\nVerify that the installation is correctly configured.\n\nA successful installation can be verified by running the following command in Python:\nimport gurobipy as gp\nprint(gp.gurobi.version())\nIf this command executes without errors and prints the Gurobi version information, the solver and its Python interface are correctly installed and ready to use."
  },
  {
    "objectID": "lectures/lecture2.html#the-gurobi-python-api-core-concepts",
    "href": "lectures/lecture2.html#the-gurobi-python-api-core-concepts",
    "title": "Lecture 2 ‚Äî Mathematical Programming with Python and Gurobi",
    "section": "3 The Gurobi Python API: Core Concepts",
    "text": "3 The Gurobi Python API: Core Concepts\nThe Gurobi Python API provides a programmatic interface for building and solving mathematical optimization models. At its core, a Gurobi model is composed of a small number of fundamental objects that together define the optimization problem.\nThe main building blocks are:\n\nModel The central container that holds the entire optimization problem, including variables, objective, constraints, and solver parameters.\nVariables Decision variables with specified domains (continuous, integer, binary), bounds, and optional names. Variables represent the unknown quantities the solver will determine.\nObjective A linear expression in the decision variables that is either minimized or maximized.\nConstraints Linear expressions that restrict the feasible values of the decision variables and encode the logical, physical, or resource limitations of the problem.\n\nThese objects interact through a well-defined modeling workflow that is largely independent of the specific problem being solved.\n\n\n3.1 Typical Modeling Pattern\nMost optimization models built with Gurobi follow the same high-level sequence:\n\nCreate a model to serve as the container for all components.\nAdd decision variables, specifying bounds and variable types.\nSet the objective function, indicating whether it is a minimization or maximization problem.\nAdd constraints that define feasibility.\nOptimize the model by invoking the solver.\nInspect the solution, including variable values, objective value, and solver status.\n\nThis pattern applies uniformly to LPs, ILPs, and MILPs.\n\n\n\n3.2 Example 1: Solving a Linear Program\nConsider the following linear programming problem:\n\\[\n\\begin{aligned}\n\\max\\ \\ & 3x_1 + 5x_2 \\\\\n\\text{s.t.}\\ \\ & 2x_1 + 4x_2 \\le 100, \\\\\n& x_1, x_2 \\ge 0.\n\\end{aligned}\n\\]\nPython Implementation\nimport gurobipy as gp\nfrom gurobipy import GRB\n\nmodel = gp.Model(\"lp_example\")\n\nx1 = model.addVar(lb=0, name=\"x1\")\nx2 = model.addVar(lb=0, name=\"x2\")\n\nmodel.setObjective(3*x1 + 5*x2, GRB.MAXIMIZE)\nmodel.addConstr(2*x1 + 4*x2 &lt;= 100)\n\nmodel.optimize()\nIn this code:\n\na model object is created,\ntwo continuous nonnegative variables are added,\na linear objective is defined, and\na single linear constraint is introduced.\n\nInspecting the Solution\nAfter optimization, solution information can be accessed directly from the model and variables:\nprint(\"x1 =\", x1.X)\nprint(\"x2 =\", x2.X)\nprint(\"Objective value =\", model.ObjVal)\nThe attributes .X and .ObjVal return the optimal variable values and objective value, respectively, provided that an optimal solution exists.\n\n\n\n3.3 Example 2: Integer Programming with Binary Variables\nConsider a simple knapsack problem with binary selection decisions:\n\\[\n\\begin{aligned}\n\\max\\ \\ & \\sum_j v_j x_j \\\\\n\\text{s.t.}\\ \\ & \\sum_j w_j x_j \\le W, \\\\\n& x_j \\in {0,1}.\n\\end{aligned}\n\\]\nHere, each item \\(j\\) is either selected or not, and the total weight must not exceed the capacity \\(W\\).\nPython Implementation\nv = [10, 13, 18, 31]\nw = [5, 8, 12, 20]\nW = 30\n\nmodel = gp.Model(\"knapsack\")\n\nx = model.addVars(len(v), vtype=GRB.BINARY, name=\"x\")\n\nmodel.setObjective(gp.quicksum(v[j]*x[j] for j in range(len(v))), GRB.MAXIMIZE)\nmodel.addConstr(gp.quicksum(w[j]*x[j] for j in range(len(w))) &lt;= W)\n\nmodel.optimize()\nThis example illustrates how integer variables are introduced via the vtype=GRB.BINARY argument and how summations are conveniently expressed using quicksum.\n\n\n\n3.4 Example 3: A Simple MILP with Activation\nConsider a production decision with a fixed setup cost and a capacity limit that is active only when production is enabled:\n\\[\n\\begin{aligned}\n\\min\\ \\ & F y + c x \\\\\n\\text{s.t.}\\ \\ & x \\le U y, \\\\\n& x \\ge 0,\\quad y \\in {0,1}.\n\\end{aligned}\n\\]\nPython Implementation\nF = 100\nc = 2\nU = 50\n\nmodel = gp.Model(\"milp_example\")\n\nx = model.addVar(lb=0, name=\"x\")\ny = model.addVar(vtype=GRB.BINARY, name=\"y\")\n\nmodel.setObjective(F*y + c*x, GRB.MINIMIZE)\nmodel.addConstr(x &lt;= U*y)\n\nmodel.optimize()\nThis model demonstrates a typical on‚Äìoff constraint, where a continuous variable is linked to a binary decision. Such patterns are central to MILP modeling.\n\n\n\n3.5 Solver Output and Status Codes\nAfter optimization, Gurobi reports detailed information about the outcome of the solve, including:\n\nthe solver status (optimal, infeasible, unbounded, or other termination states),\nthe objective value of the best solution found,\nthe primal values of all decision variables, and\ndual information for LPs, when applicable.\n\nIt is good practice to always check the solver status before using solution values:\nif model.status == GRB.OPTIMAL:\n    print(\"Optimal solution found\")\nelif model.status == GRB.INFEASIBLE:\n    print(\"Model is infeasible\")\n\n\n\n3.6 Modeling Errors and Debugging\nCommon sources of errors in solver-based modeling include:\n\nmissing or incorrectly specified constraints,\nincorrect variable domains (e.g., using continuous variables instead of binaries),\noverly large big-\\(M\\) values that weaken the formulation, and\nmutually contradictory constraints that make the model infeasible.\n\nGurobi provides diagnostic tools such as Irreducible Infeasible Subsystem (IIS) computation, which helps identify minimal sets of conflicting constraints and is invaluable for debugging complex models.\n\n\n\n3.7 Best Practices for Solver-Based Modeling\nDeveloping robust and efficient optimization models requires both sound mathematical formulation and disciplined implementation practices. The following guidelines help ensure correctness, interpretability, and computational efficiency.\n\nClearly separate data, model, and solution logic. Organize code so that problem data, model construction, and solution analysis are handled in distinct sections or modules. This separation improves readability, facilitates debugging, and makes it easier to modify or extend the model.\nStart with small test instances. Begin with simplified or reduced-size instances where the expected solution can be reasoned about manually. This helps validate the formulation and identify modeling errors before scaling up to larger or more complex instances.\nVerify LP relaxations before enforcing integrality. Solve the LP relaxation of an ILP or MILP to check feasibility, constraint logic, and objective behavior. A correct and well-behaved LP relaxation is a strong indicator that the integer model is formulated properly.\nAlways inspect solver status before using results. Never assume that a solver call returns an optimal solution. Check the solver status to confirm optimality or identify infeasibility, unboundedness, or early termination before interpreting variable values or objective outcomes.\n\n\n\n\n3.8 Takeaways\n\nSolvers are algorithmic engines that turn mathematical models into solutions\nPython provides a flexible and powerful modeling environment\nGurobi supports LP, ILP, and MILP through a unified API\nCareful modeling is as important as solver choice"
  },
  {
    "objectID": "lectures/lecture2.html#mini-exercises",
    "href": "lectures/lecture2.html#mini-exercises",
    "title": "Lecture 2 ‚Äî Mathematical Programming with Python and Gurobi",
    "section": "4 Mini Exercises",
    "text": "4 Mini Exercises\n\nExtending a linear program with an additional resource constraint. Starting from the LP example solved earlier, introduce a second resource constraint (for example, a limit on raw material or machine time).\n\nFormulate the new constraint mathematically.\nUpdate the Python implementation accordingly.\nSolve the modified model and compare the new optimal solution with the original one. Question: How does the additional constraint change the feasible region and the optimal solution?\n\nKnapsack with a cardinality constraint. Extend the knapsack model by limiting the number of items that can be selected.\n\nIntroduce a parameter \\(p\\) representing the maximum number of items that may be chosen.\nAdd a cardinality constraint of the form \\(\\sum_j x_j \\le p\\).\nSolve the resulting ILP and analyze how the optimal solution differs from the unconstrained knapsack. Question: Under what conditions does the cardinality constraint become binding?\n\nReplacing big-\\(M\\) with an indicator constraint. Consider the MILP example with a setup decision and production variable.\n\nReformulate the constraint \\(x \\le U y\\) using an indicator constraint of the form ‚Äú\\(y = 0 \\Rightarrow x = 0\\)‚Äù.\nImplement the indicator-based formulation in Gurobi‚Äôs Python API.\nSolve both formulations and compare solver behavior. Question: Do you observe any differences in model clarity, numerical stability, or solution time?\n\n\nThese exercises are designed to reinforce both modeling concepts and practical solver usage, and to highlight how small formulation changes can significantly affect model behavior."
  },
  {
    "objectID": "lectures/lecture3.html",
    "href": "lectures/lecture3.html",
    "title": "Lecture 3 ‚Äî Why Exact Methods Fail: Complexity, Scalability, and Motivation for Soft Computing",
    "section": "",
    "text": "By the end of this lecture, students should be able to:\n\nunderstand the computational limitations of exact optimization methods\n\ndevelop intuition about NP-hardness and combinatorial explosion\n\nexplain why MILP formulations become impractical for large-scale problems\n\ndistinguish worst-case complexity from practical performance\n\nunderstand the role of heuristics and metaheuristics as scalable alternatives\n\nmotivate the need for soft computing approaches in real-world optimization"
  },
  {
    "objectID": "lectures/lecture3.html#learning-objectives",
    "href": "lectures/lecture3.html#learning-objectives",
    "title": "Lecture 3 ‚Äî Why Exact Methods Fail: Complexity, Scalability, and Motivation for Soft Computing",
    "section": "",
    "text": "By the end of this lecture, students should be able to:\n\nunderstand the computational limitations of exact optimization methods\n\ndevelop intuition about NP-hardness and combinatorial explosion\n\nexplain why MILP formulations become impractical for large-scale problems\n\ndistinguish worst-case complexity from practical performance\n\nunderstand the role of heuristics and metaheuristics as scalable alternatives\n\nmotivate the need for soft computing approaches in real-world optimization"
  },
  {
    "objectID": "lectures/lecture3.html#from-exact-optimization-to-soft-computing",
    "href": "lectures/lecture3.html#from-exact-optimization-to-soft-computing",
    "title": "Lecture 3 ‚Äî Why Exact Methods Fail: Complexity, Scalability, and Motivation for Soft Computing",
    "section": "2 From Exact Optimization to Soft Computing",
    "text": "2 From Exact Optimization to Soft Computing\nIn the previous lectures, exact optimization methods such as LP, ILP, and MILP were introduced together with modern solvers like Gurobi. These tools represent the state of the art in exact decision-making, providing provably optimal solutions when computationally feasible. They form the backbone of many industrial decision support systems, especially in domains where solution quality, correctness, and optimality guarantees are critical.\nHowever, despite continuous algorithmic and hardware advances, exact methods do not scale indefinitely. As problem size and structural complexity increase, many practically relevant optimization problems rapidly exceed the computational limits of exact solvers. This limitation is not merely an implementation issue, but a consequence of fundamental theoretical barriers.\nUnderstanding why exact methods fail to scale is essential before introducing soft computing techniques, which deliberately trade optimality guarantees for scalability, flexibility, and robustness. This lecture therefore serves as the conceptual bridge between exact mathematical programming and heuristic and metaheuristic approaches that dominate large-scale optimization practice.\n\n\n2.1 Computational Complexity: An Intuitive View\nOptimization problems differ not only in how difficult they are to model, but also in how difficult they are to solve computationally. This difficulty is captured by the notion of computational complexity, which describes how the amount of computation required grows as the problem size increases.\nAt a high level, algorithms fall into fundamentally different growth regimes.\nPolynomial-Time vs Exponential Growth\n\nPolynomial-time algorithms scale relatively well with problem size.\n\nTypical runtime grows like \\(n^2\\), \\(n^3\\), or another fixed power of the input size \\(n\\).\nLinear programming, when solved using interior-point methods, belongs to this category from a theoretical perspective.\n\nExponential-time algorithms scale extremely poorly.\n\nRuntime grows like \\(2^n\\), \\(n!\\), or similarly fast-growing functions.\nEven modest increases in problem size lead to dramatic increases in computational effort.\n\n\nThis distinction explains a key empirical observation: LPs with millions of variables can often be solved routinely, while ILPs or MILPs with only a few thousand binary variables may already be computationally intractable.\n\n\n\n2.2 NP-Hardness: Practical Intuition\nMost integer and mixed-integer optimization problems are NP-hard. Informally, NP-hardness means that:\n\nno algorithm is known that can solve all instances of the problem efficiently (in polynomial time), and\nthe difficulty of solving the problem grows combinatorially with problem size in the worst case.\n\nFrom a practical standpoint, NP-hardness has several important implications.\nWhat NP-Hardness Means in Practice\nNP-hardness does not imply that every instance of an NP-hard problem is impossible to solve. Instead, it means:\n\nsmall or moderately sized instances may be solved optimally,\ninstances with special structure may be computationally easy, but\nin the worst case, the solver must explore an exponential number of possibilities.\n\nAs problem size increases, the solver may experience dramatic and unpredictable increases in runtime, even when only a small number of variables or constraints are added.\nClassic NP-hard optimization problems include:\n\nthe knapsack problem,\nthe traveling salesman problem,\nset covering and set packing problems,\nfacility location problems, and\nscheduling problems with setups or sequence-dependent constraints.\n\nMost real-world planning, design, and allocation problems contain one or more of these NP-hard problems as embedded substructures, which fundamentally limits the scalability of exact approaches.\n\n\n\n2.3 Combinatorial Explosion\nThe core source of difficulty in ILP and MILP is combinatorial explosion.\nBinary Variables and Search Space Size\nBinary decision variables encode discrete choices. If a model contains \\(n\\) binary variables, then the total number of possible assignments is:\n\\[\n2^n\n\\]\nThis growth is extremely rapid:\n\n\\(n = 20\\) ‚Üí approximately \\(10^6\\) combinations\n\\(n = 40\\) ‚Üí approximately \\(10^{12}\\) combinations\n\\(n = 100\\) ‚Üí far beyond what can be enumerated in any realistic timeframe\n\nEven though modern solvers use advanced techniques such as bounding, cutting planes, and intelligent branching to avoid full enumeration, the underlying exponential growth cannot be eliminated. In the worst case, the solver must still consider an astronomically large search space.\nThis combinatorial explosion is the fundamental reason why exact enumeration-based methods eventually fail to scale, regardless of implementation quality or hardware improvements.\n\nTogether, these observations explain the central motivation for soft computing: when exact optimality becomes computationally unattainable, alternative methods are required that can deliver high-quality solutions within acceptable time limits."
  },
  {
    "objectID": "lectures/lecture3.html#how-milp-solvers-work-high-level",
    "href": "lectures/lecture3.html#how-milp-solvers-work-high-level",
    "title": "Lecture 3 ‚Äî Why Exact Methods Fail: Complexity, Scalability, and Motivation for Soft Computing",
    "section": "3 How MILP Solvers Work (High-Level)",
    "text": "3 How MILP Solvers Work (High-Level)\nModern MILP solvers are built around branch-and-bound and its enhanced variant, branch-and-cut. These frameworks systematically explore the space of integer solutions while using linear programming relaxations to guide and prune the search.\nAt a conceptual level, the solution process proceeds as follows:\n\nSolve the LP relaxation The integrality constraints are temporarily relaxed, allowing integer variables to take fractional values. This provides a bound on the optimal objective value.\nCheck integrality If the LP solution satisfies all integrality requirements, it is an optimal solution to the MILP, and the algorithm terminates.\nBranch on a fractional variable If one or more integer variables take fractional values, the solver selects a variable and creates subproblems by fixing it to different integer values.\nRecursively explore subproblems Each subproblem defines a node in a search tree. The solver repeats the process of solving LP relaxations and branching.\nPrune using bounds If a subproblem cannot yield a better solution than the best one found so far, it is discarded without further exploration.\n\nBranch-and-cut strengthens this framework by dynamically adding cutting planes that eliminate fractional solutions without removing any integer-feasible solutions, thereby tightening LP relaxations.\nAlthough highly effective in practice, this process can still generate millions or even billions of search tree nodes for large, weakly formulated, or poorly structured models.\n\n\n3.1 Why MILP Becomes Impractical\nDespite decades of algorithmic improvements, MILP solvers face fundamental limitations that cannot be fully overcome.\nModel Size:\n\nThe number of variables and constraints can grow rapidly with problem size and modeling detail.\nLarge models consume significant memory and computational resources.\nPresolve techniques may fail to substantially reduce very large or complex formulations.\n\nWeak LP Relaxations:\n\nLarge integrality gaps lead to poor bounds and slow convergence.\nWeak formulations reduce the effectiveness of pruning in the search tree.\nBig-\\(M\\) constraints often severely degrade relaxation quality and numerical stability.\n\nTime Constraints:\n\nMany real-world applications require decisions within seconds or minutes.\nExact solvers may require hours or days to prove optimality or even feasibility.\nWhen time limits are imposed, solvers may return suboptimal solutions or fail to find any feasible solution at all.\n\n\n\n\n3.2 Real-World Requirements vs Exact Optimality\nIn practical decision-making environments, the emphasis is often not on mathematical optimality, but on usable solutions within limited time. Decision-makers typically value:\n\ngood-quality solutions obtained quickly,\nrobustness against data uncertainty and modeling imperfections,\nscalability to large and complex instances, and\nflexibility to incorporate domain-specific constraints and preferences.\n\nAs a result, exact optimality is frequently less important than responsiveness and solution quality. This fundamental mismatch between theoretical optimality guarantees and practical requirements motivates the use of alternative solution paradigms, particularly heuristics, metaheuristics, and other soft computing approaches that emphasize scalability and adaptability over exactness."
  },
  {
    "objectID": "lectures/lecture3.html#motivation-for-soft-computing",
    "href": "lectures/lecture3.html#motivation-for-soft-computing",
    "title": "Lecture 3 ‚Äî Why Exact Methods Fail: Complexity, Scalability, and Motivation for Soft Computing",
    "section": "4 Motivation for Soft Computing",
    "text": "4 Motivation for Soft Computing\nSoft computing refers to a broad class of computational methods that deliberately relax the requirement of exact optimality in exchange for properties that are often more valuable in practice, namely:\n\nscalability to large and complex problem instances,\nflexibility in modeling nonstandard, nonlinear, or problem-specific constraints,\nrobustness with respect to noisy, incomplete, or uncertain data, and\nease of implementation and adaptation to new problem variants.\n\nRather than guaranteeing a mathematically optimal solution, soft computing methods aim to produce good or near-optimal solutions within acceptable computational time. This trade-off is often essential when dealing with large-scale, real-world decision problems where exact methods fail to deliver timely or usable solutions.\n\n\n4.1 Heuristics and Metaheuristics as Alternatives\nSoft computing encompasses a wide range of heuristic and metaheuristic approaches designed to explore large solution spaces efficiently.\nCommon categories include:\n\nConstructive heuristics\n\nbuild a feasible solution step by step using fast, problem-specific rules,\noften used to generate initial solutions.\n\nLocal search methods\n\nstart from an initial solution and iteratively improve it by exploring a neighborhood,\nfocus on intensification around promising regions of the search space.\n\nMetaheuristics\n\ngeneral-purpose algorithmic frameworks that guide the search process,\nbalance exploration and exploitation to escape local optima,\nexamples include simulated annealing, tabu search, and genetic algorithms.\n\n\nThese methods share several important characteristics:\n\nthey do not require convexity or linearity,\nthey naturally handle discrete, continuous, and mixed decision variables,\nthey scale well to very large problem instances, and\nthey can be easily hybridized with exact optimization techniques.\n\n\n\n\n4.2 Exact Methods vs Soft Computing: A Comparison\nThe following table highlights the fundamental differences between exact optimization methods and soft computing approaches.\n\n\n\n\n\n\n\n\nAspect\nExact Methods (MILP)\nSoft Computing\n\n\n\n\nOptimality guarantee\nYes\nNo\n\n\nScalability\nLimited\nHigh\n\n\nRuntime predictability\nLow\nHigh\n\n\nFlexibility\nModerate\nVery high\n\n\nModeling effort\nHigh\nModerate\n\n\nPractical role\nBaseline, validation, benchmarking\nPrimary solution method\n\n\n\nRather than being competing paradigms, these approaches address different needs. Exact methods excel when problem size and structure permit, while soft computing dominates in large-scale, time-critical, or highly complex settings.\n\n\n\n4.3 Matheuristics and Hybrid Approaches\nA powerful modern paradigm in optimization is hybrid optimization, often referred to as matheuristics. These approaches combine the strengths of exact mathematical programming and soft computing techniques.\nTypical hybrid strategies include:\n\nusing MILP models to capture problem structure and compute bounds,\ngenerating high-quality initial solutions using heuristics,\nimproving incumbent solutions via local search or metaheuristics, and\napplying exact solvers selectively on reduced or restricted subproblems.\n\nThis combination leverages the rigor of exact optimization and the scalability of soft computing, and it represents the dominant solution paradigm in many contemporary research and industrial applications.\n\n\n\n4.4 Takeaways\n\nNP-hardness explains why many optimization problems do not scale\n\nBinary decisions lead to exponential growth in solution space\n\nMILP solvers are powerful but fundamentally limited\n\nExact optimality is often impractical for large problems\n\nSoft computing provides scalable, flexible alternatives\n\nModern optimization increasingly relies on hybrid methods"
  },
  {
    "objectID": "lectures/lecture3.html#mini-exercises",
    "href": "lectures/lecture3.html#mini-exercises",
    "title": "Lecture 3 ‚Äî Why Exact Methods Fail: Complexity, Scalability, and Motivation for Soft Computing",
    "section": "5 Mini Exercises",
    "text": "5 Mini Exercises\n\nCombinatorial explosion with binary variables. A model has \\(n = 50\\) binary decision variables.\n\nCompute the number of possible assignments, \\(2^{50}\\).\nExpress it approximately in scientific notation.\nExplain why brute-force enumeration is infeasible even with very fast computers. Hint: Compare \\(2^{50}\\) to \\(10^{12}\\) and consider time per evaluation.\n\nNear-optimal solutions in practice. Identify a real-life optimization problem where a near-optimal solution is acceptable, such as routing deliveries, shift scheduling, or production planning.\n\nDescribe the decision variables and constraints at a high level.\nExplain why computing an exact optimal solution is not necessary or not practical. Hint: Consider time pressure, uncertainty, changing data, or human preferences.\n\nHeuristics as warm starts for MILP. MILP solvers benefit significantly from good feasible solutions early in the search.\n\nPropose one heuristic that can generate a feasible solution quickly for a MILP of your choice.\nExplain how this heuristic solution could be passed as an initial solution (warm start) to an MILP solver.\nDiscuss why having a strong incumbent helps branch-and-bound. Hint: Better incumbents improve pruning by tightening the bound gap.\n\nSensitivity to one additional binary variable. Consider a problem where the decision space is controlled by binary variables.\n\nExplain how adding one more binary variable changes the theoretical search space size.\nProvide an example scenario where adding one additional feature, option, or constraint introduces a new binary decision and increases difficulty substantially. Hint: Show how \\(2^n\\) becomes \\(2^{n+1}\\) and interpret this doubling effect."
  }
]